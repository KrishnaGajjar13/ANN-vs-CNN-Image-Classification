{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "38emhYi_3Ci9",
        "outputId": "c1b21633-dbbd-4a74-bd45-5c5cb200e081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 68.7M  100 68.7M    0     0  11.8M      0  0:00:05  0:00:05 --:--:-- 16.4M\n",
            "Archive:  /content/Fashion_MNIST/fashionmnist.zip\n",
            "  inflating: /content/Fashion_MNIST/fashion-mnist_test.csv  \n",
            "  inflating: /content/Fashion_MNIST/fashion-mnist_train.csv  \n",
            "  inflating: /content/Fashion_MNIST/t10k-images-idx3-ubyte  \n",
            "  inflating: /content/Fashion_MNIST/t10k-labels-idx1-ubyte  \n",
            "  inflating: /content/Fashion_MNIST/train-images-idx3-ubyte  \n",
            "  inflating: /content/Fashion_MNIST/train-labels-idx1-ubyte  \n"
          ]
        }
      ],
      "source": [
        "!curl -L -o /content/Fashion_MNIST/fashionmnist.zip https://www.kaggle.com/api/v1/datasets/download/zalando-research/fashionmnist\n",
        "!unzip /content/Fashion_MNIST/fashionmnist.zip -d /content/Fashion_MNIST/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "import torch, torchinfo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwx1gzq79LeT",
        "outputId": "a9c04d2a-8ee4-4e25-8917-a289512db908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('/content/Fashion_MNIST/fashion-mnist_train.csv')\n",
        "X = df.iloc[:,1:].values\n",
        "y = df.iloc[:,0].values\n",
        "\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.25, random_state=69)\n",
        "X_train = X_train/255.0\n",
        "x_test = X_test/255.0\n"
      ],
      "metadata": {
        "id": "w-glCx6M-D1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = torch.tensor(features , dtype = torch.float32)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.labels[index]\n",
        "\n"
      ],
      "metadata": {
        "id": "TeX-eclB-S4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory= True)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory= True)"
      ],
      "metadata": {
        "id": "NaIhY4sQ_8gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NN(torch.nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(64, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "epochs = 100\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "CJxCRFUOAKLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(X_train.shape[1])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,weight_decay = 1e-4)\n"
      ],
      "metadata": {
        "id": "jMn-LqpoXqFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_epochs_loss = 0\n",
        "  for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    preds = model(data)\n",
        "\n",
        "    loss = criterion(preds,targets)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    total_epochs_loss = total_epochs_loss + loss.item()\n",
        "\n",
        "  avg_loss = total_epochs_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch+1}, Loss: {avg_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "collapsed": true,
        "id": "fWiOMEnaX6Ri",
        "outputId": "fc72c04d-5b6b-4309-df4a-18d7d36ace0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.6091243498657474\n",
            "Epoch: 2, Loss: 0.4737097313197352\n",
            "Epoch: 3, Loss: 0.4396821263205861\n",
            "Epoch: 4, Loss: 0.4158070398694501\n",
            "Epoch: 5, Loss: 0.3951145104783261\n",
            "Epoch: 6, Loss: 0.3832135838062609\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0628592ec536>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# cache this on the first invocation to avoid adding too much overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data, targets in test_loader:\n",
        "    preds = model(data)\n",
        "\n",
        "    _, predicted = torch.max(preds.data, 1)\n",
        "    total += targets.size(0)\n",
        "    correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100*correct/total}')\n",
        "\n",
        "# Accuracy Train VS Test set\n",
        "\n",
        "total_2 = 0\n",
        "correct_2 = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data, targets in train_loader:\n",
        "    preds = model(data)\n",
        "\n",
        "    _, predicted = torch.max(preds.data, 1)\n",
        "    total_2 += targets.size(0)\n",
        "    correct_2 += (predicted == targets).sum().item()\n",
        "print(f'Accuracy: {100*correct_2/total_2}')\n",
        "\n",
        "# Test accuracy decreased by 1% and on Train is by 9% which helps in avoiding overfitting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEVWuGr4Y6_z",
        "outputId": "461719ed-a648-4091-84f2-e25530ed7647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.08\n",
            "Accuracy: 89.54222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NN(torch.nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(64, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "GN72L-kYlUFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "TDm2cofUqePS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyNN(nn.Module):\n",
        "  def __init__(self,input_dims,output_dim, num_hidden_layers, neurons_per_layer):\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for i in range(num_hidden_layers):\n",
        "      layers.append(nn.Linear(input_dims,neurons_per_layer))\n",
        "      layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(p=0.25))\n",
        "      input_dims = neurons_per_layer\n",
        "\n",
        "    layers.append(nn.Linear(input_dims,output_dim))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "\n",
        "#objective function\n",
        "def objective(trial):\n",
        "\n",
        "  #State Search\n",
        "  num_hidden_layers =   trial.suggest_int(\"num_hidden_layers\" ,1,5)\n",
        "  neurons_per_layer = trial.suggest_int(\"neurons_per_layer\" ,8,128,step = 8)\n",
        "\n",
        "  #model init\n",
        "  input_dim = 784\n",
        "  output_dim = 10\n",
        "  model = MyNN(input_dim,output_dim, num_hidden_layers, neurons_per_layer)\n",
        "  model.to(device)  # Move model to device\n",
        "\n",
        "  #loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  #params init\n",
        "  learning_rate = 0.01\n",
        "  epochs = 50\n",
        "\n",
        "  #optimizer selection\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,weight_decay = 1e-4)\n",
        "\n",
        "\n",
        "  #training loop\n",
        "  for epoch in range(epochs):\n",
        "    for data, targets in train_loader:\n",
        "      data, targets = data.to(device), targets.to(device) # Move data to device\n",
        "      preds = model(data)\n",
        "\n",
        "      loss = criterion(preds,targets)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "  #evaluation\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "      data, targets = data.to(device), targets.to(device) # Move data to device\n",
        "      preds = model(data)\n",
        "\n",
        "      _, predicted = torch.max(preds.data, 1)\n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "      accuracy = 100*correct/total\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "PWqftR9Ab5z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v9usFxfoW4d",
        "outputId": "b1ea815d-bec6-4080-f3a8-92e1478c3e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "study = optuna.create_study(direction = 'maximize')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGocNmU4obtI",
        "outputId": "3de06896-6268-4965-d397-10ff5f578644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-05 10:51:37,017] A new study created in memory with name: no-name-b6aa8ce6-46f3-411f-b119-b7e4f5f7d646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CfKG6epoqBf",
        "outputId": "f686c457-5c76-4e23-9bea-79cd38310743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-05 10:55:33,478] Trial 0 finished with value: 81.35333333333334 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 112}. Best is trial 0 with value: 81.35333333333334.\n",
            "[I 2025-02-05 10:59:47,786] Trial 1 finished with value: 29.026666666666667 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 8}. Best is trial 0 with value: 81.35333333333334.\n",
            "[I 2025-02-05 11:02:25,916] Trial 2 finished with value: 81.16 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 72}. Best is trial 0 with value: 81.35333333333334.\n",
            "[I 2025-02-05 11:05:05,019] Trial 3 finished with value: 82.02 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 96}. Best is trial 3 with value: 82.02.\n",
            "[I 2025-02-05 11:08:15,931] Trial 4 finished with value: 82.13333333333334 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 48}. Best is trial 4 with value: 82.13333333333334.\n",
            "[I 2025-02-05 11:10:55,580] Trial 5 finished with value: 83.79333333333334 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 80}. Best is trial 5 with value: 83.79333333333334.\n",
            "[I 2025-02-05 11:15:09,594] Trial 6 finished with value: 75.56 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 32}. Best is trial 5 with value: 83.79333333333334.\n",
            "[I 2025-02-05 11:17:16,923] Trial 7 finished with value: 80.06666666666666 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 64}. Best is trial 5 with value: 83.79333333333334.\n",
            "[I 2025-02-05 11:20:29,341] Trial 8 finished with value: 83.53333333333333 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 48}. Best is trial 5 with value: 83.79333333333334.\n",
            "[I 2025-02-05 11:23:07,012] Trial 9 finished with value: 79.3 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 120}. Best is trial 5 with value: 83.79333333333334.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(study.best_params)\n",
        "print(study.best_trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRFmH61uouA5",
        "outputId": "9e740ed9-db2e-4dc0-e5d1-aaa081d12dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num_hidden_layers': 2, 'neurons_per_layer': 80}\n",
            "FrozenTrial(number=5, state=1, values=[83.79333333333334], datetime_start=datetime.datetime(2025, 2, 5, 11, 8, 15, 937463), datetime_complete=datetime.datetime(2025, 2, 5, 11, 10, 55, 580414), params={'num_hidden_layers': 2, 'neurons_per_layer': 80}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'num_hidden_layers': IntDistribution(high=5, log=False, low=1, step=1), 'neurons_per_layer': IntDistribution(high=128, log=False, low=8, step=8)}, trial_id=5, value=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyNN(nn.Module):\n",
        "  def __init__(self,input_dims,output_dim, num_hidden_layers, neurons_per_layer,dropout_rate):\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for i in range(num_hidden_layers):\n",
        "      layers.append(nn.Linear(input_dims,neurons_per_layer))\n",
        "      layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(dropout_rate))\n",
        "      input_dims = neurons_per_layer\n",
        "\n",
        "    layers.append(nn.Linear(input_dims,output_dim))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "\n",
        "#objective function\n",
        "def objective(trial):\n",
        "\n",
        "  #State Search\n",
        "  num_hidden_layers =   trial.suggest_int(\"num_hidden_layers\" ,1,5)\n",
        "  neurons_per_layer = trial.suggest_int(\"neurons_per_layer\" ,8,128,step = 8)\n",
        "  epochs = trial.suggest_int(\"epochs\" , 10, 100, step = 10)\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "  dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [16,32,64,128])\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer_name\" , ['Adam', 'SGD', 'RMSprop'])\n",
        "  weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  #model init\n",
        "  input_dim = 784\n",
        "  output_dim = 10\n",
        "  model = MyNN(input_dim,output_dim, num_hidden_layers, neurons_per_layer,dropout_rate)\n",
        "  model.to(device)  # Move model to device\n",
        "\n",
        "\n",
        "  train_dataset = CustomDataset(X_train, y_train)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory= True)\n",
        "  test_dataset = CustomDataset(X_test, y_test)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory= True)\n",
        "\n",
        "  #loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  #params init\n",
        "\n",
        "  #optimizer selection\n",
        "  if optimizer_name == 'Adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = weight_decay)\n",
        "  elif optimizer_name == 'SGD':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,weight_decay = weight_decay)\n",
        "  else:\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate,weight_decay = weight_decay)\n",
        "\n",
        "  #training loop\n",
        "  for epoch in range(epochs):\n",
        "    for data, targets in train_loader:\n",
        "      data, targets = data.to(device), targets.to(device) # Move data to device\n",
        "      preds = model(data)\n",
        "\n",
        "      loss = criterion(preds,targets)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "  #evaluation\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "      data, targets = data.to(device), targets.to(device) # Move data to device\n",
        "      preds = model(data)\n",
        "\n",
        "      _, predicted = torch.max(preds.data, 1)\n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "      accuracy = 100*correct/total\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "VRnENH_W2fea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "study = optuna.create_study(direction = 'maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Z_GnyA5TQS",
        "outputId": "67bf3885-2925-4a22-bea6-f5bab904a3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-05 11:37:48,121] A new study created in memory with name: no-name-0e1c545b-8b84-447f-b2b3-a6221fa9431b\n",
            "[I 2025-02-05 11:40:45,628] Trial 0 finished with value: 65.34 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 104, 'epochs': 90, 'learning_rate': 0.007928745622192982, 'dropout_rate': 0.5, 'batch_size': 64, 'optimizer_name': 'Adam', 'weight_decay': 0.0029908089900752555}. Best is trial 0 with value: 65.34.\n",
            "[I 2025-02-05 11:43:05,058] Trial 1 finished with value: 70.74 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 80, 'epochs': 90, 'learning_rate': 0.0010284710071389823, 'dropout_rate': 0.1, 'batch_size': 64, 'optimizer_name': 'RMSprop', 'weight_decay': 0.0022222267682185082}. Best is trial 1 with value: 70.74.\n",
            "[I 2025-02-05 11:44:18,353] Trial 2 finished with value: 72.68 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 80, 'epochs': 60, 'learning_rate': 0.017194953417692668, 'dropout_rate': 0.1, 'batch_size': 128, 'optimizer_name': 'SGD', 'weight_decay': 0.012808980653471823}. Best is trial 2 with value: 72.68.\n",
            "[I 2025-02-05 11:45:37,190] Trial 3 finished with value: 77.46666666666667 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 120, 'epochs': 30, 'learning_rate': 0.052195007288881, 'dropout_rate': 0.2, 'batch_size': 32, 'optimizer_name': 'SGD', 'weight_decay': 3.241357244128743e-05}. Best is trial 3 with value: 77.46666666666667.\n",
            "[I 2025-02-05 11:49:05,346] Trial 4 finished with value: 53.653333333333336 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 128, 'epochs': 70, 'learning_rate': 0.0506558147610738, 'dropout_rate': 0.1, 'batch_size': 64, 'optimizer_name': 'Adam', 'weight_decay': 4.599587877925062e-05}. Best is trial 3 with value: 77.46666666666667.\n",
            "[I 2025-02-05 11:49:25,591] Trial 5 finished with value: 46.06666666666667 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 16, 'epochs': 10, 'learning_rate': 0.07375675880240445, 'dropout_rate': 0.30000000000000004, 'batch_size': 64, 'optimizer_name': 'Adam', 'weight_decay': 0.0004972171360207722}. Best is trial 3 with value: 77.46666666666667.\n",
            "[I 2025-02-05 11:50:39,234] Trial 6 finished with value: 29.42 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 120, 'epochs': 50, 'learning_rate': 0.05499301220633383, 'dropout_rate': 0.5, 'batch_size': 128, 'optimizer_name': 'Adam', 'weight_decay': 0.011425299878945729}. Best is trial 3 with value: 77.46666666666667.\n",
            "[I 2025-02-05 11:51:28,004] Trial 7 finished with value: 80.91333333333333 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 88, 'epochs': 30, 'learning_rate': 3.000204632329585e-05, 'dropout_rate': 0.2, 'batch_size': 64, 'optimizer_name': 'Adam', 'weight_decay': 0.0002421726948998241}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 11:52:19,942] Trial 8 finished with value: 61.75333333333333 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 40, 'epochs': 40, 'learning_rate': 0.05084054435634064, 'dropout_rate': 0.30000000000000004, 'batch_size': 128, 'optimizer_name': 'Adam', 'weight_decay': 0.00030046886768349344}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 11:52:57,850] Trial 9 finished with value: 78.84 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 48, 'epochs': 40, 'learning_rate': 0.0012118483532516475, 'dropout_rate': 0.5, 'batch_size': 128, 'optimizer_name': 'RMSprop', 'weight_decay': 0.0004796571465041552}. Best is trial 7 with value: 80.91333333333333.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ8y8je29XuV",
        "outputId": "5ffd0029-d350-4962-dbe3-417598d0f202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-05 11:54:56,216] Trial 10 finished with value: 48.06666666666667 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 96, 'epochs': 10, 'learning_rate': 1.0253643833231317e-05, 'dropout_rate': 0.2, 'batch_size': 16, 'optimizer_name': 'SGD', 'weight_decay': 0.08510751785539593}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 11:57:28,602] Trial 11 finished with value: 80.07333333333334 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 48, 'epochs': 30, 'learning_rate': 2.9714068613000976e-05, 'dropout_rate': 0.4, 'batch_size': 16, 'optimizer_name': 'RMSprop', 'weight_decay': 0.00011914776857871813}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 11:59:10,508] Trial 12 finished with value: 76.79333333333334 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 56, 'epochs': 20, 'learning_rate': 1.5668232083875016e-05, 'dropout_rate': 0.4, 'batch_size': 16, 'optimizer_name': 'RMSprop', 'weight_decay': 8.675793351114669e-05}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 12:02:21,737] Trial 13 finished with value: 73.19333333333333 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 24, 'epochs': 30, 'learning_rate': 6.725099911001745e-05, 'dropout_rate': 0.4, 'batch_size': 16, 'optimizer_name': 'RMSprop', 'weight_decay': 1.5499125274422422e-05}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 12:07:53,660] Trial 14 finished with value: 76.30666666666667 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 64, 'epochs': 70, 'learning_rate': 0.00011096054829419394, 'dropout_rate': 0.4, 'batch_size': 32, 'optimizer_name': 'RMSprop', 'weight_decay': 0.00012028559107368473}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 12:10:31,004] Trial 15 finished with value: 79.88 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 32, 'epochs': 30, 'learning_rate': 7.818762361604243e-05, 'dropout_rate': 0.2, 'batch_size': 16, 'optimizer_name': 'Adam', 'weight_decay': 0.0001677278759022275}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 12:12:04,090] Trial 16 finished with value: 79.2 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 80, 'epochs': 50, 'learning_rate': 0.000256960123899352, 'dropout_rate': 0.30000000000000004, 'batch_size': 64, 'optimizer_name': 'RMSprop', 'weight_decay': 1.0695612435896473e-05}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 12:14:40,453] Trial 17 finished with value: 80.10666666666667 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 96, 'epochs': 20, 'learning_rate': 2.443068897239082e-05, 'dropout_rate': 0.4, 'batch_size': 16, 'optimizer_name': 'RMSprop', 'weight_decay': 0.0013870033509598462}. Best is trial 7 with value: 80.91333333333333.\n",
            "[I 2025-02-05 12:16:18,140] Trial 18 finished with value: 81.17333333333333 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 96, 'epochs': 20, 'learning_rate': 0.0003970309320319061, 'dropout_rate': 0.2, 'batch_size': 32, 'optimizer_name': 'Adam', 'weight_decay': 0.0018042887215681785}. Best is trial 18 with value: 81.17333333333333.\n",
            "[I 2025-02-05 12:17:14,482] Trial 19 finished with value: 75.70666666666666 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 104, 'epochs': 10, 'learning_rate': 0.00034998156142180246, 'dropout_rate': 0.2, 'batch_size': 32, 'optimizer_name': 'Adam', 'weight_decay': 0.005046373908518986}. Best is trial 18 with value: 81.17333333333333.\n"
          ]
        }
      ]
    }
  ]
}